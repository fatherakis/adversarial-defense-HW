{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2023-12-18T10:59:15.788631Z",
          "iopub.status.busy": "2023-12-18T10:59:15.787823Z",
          "iopub.status.idle": "2023-12-18T10:59:56.425178Z",
          "shell.execute_reply": "2023-12-18T10:59:56.424048Z",
          "shell.execute_reply.started": "2023-12-18T10:59:15.788586Z"
        },
        "id": "AWUJn5D1x1nn",
        "outputId": "14c6f18c-786f-4ebd-c2af-d190db2ef720",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip3 install matplotlib colorama\n",
        "!pip3 install adversarial-robustness-toolbox\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-18T10:59:56.428163Z",
          "iopub.status.busy": "2023-12-18T10:59:56.427843Z",
          "iopub.status.idle": "2023-12-18T11:00:01.443317Z",
          "shell.execute_reply": "2023-12-18T11:00:01.442254Z",
          "shell.execute_reply.started": "2023-12-18T10:59:56.428136Z"
        },
        "id": "eTw0TbFKx1nu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch.quantization import MovingAverageMinMaxObserver\n",
        "from torch.ao.quantization.observer import MinMaxObserver\n",
        "from torch.quantization import QuantStub, DeQuantStub\n",
        "from colorama import Fore, Style\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.utils import load_cifar10\n",
        "from art.preprocessing.standardisation_mean_std import StandardisationMeanStdPyTorch\n",
        "from art.attacks.evasion.hop_skip_jump import HopSkipJump\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "from math import log10, sqrt\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "def accuracy(output, target):\n",
        "    \"\"\" Computes the top 1 accuracy \"\"\"\n",
        "    with torch.no_grad():\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(1, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        correct_one = correct[:1].view(-1).float().sum(0, keepdim=True)\n",
        "        return correct_one.mul_(100.0 / batch_size).item()\n",
        "\n",
        "def predict(img):\n",
        "  img = torch.from_numpy(img)\n",
        "  img = F.normalize(img, [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
        "  return img.numpy()\n",
        "\n",
        "\n",
        "def print_size_of_model(model):\n",
        "    \"\"\" Prints the real size of the model \"\"\"\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "\n",
        "def train(model: nn.Module, dataloader: DataLoader, cuda=False, q=False):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)#, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n",
        "    model.train()\n",
        "    for epoch in range(1):  # loop over the dataset multiple times\n",
        "        running_loss = AverageMeter('loss')\n",
        "        acc = AverageMeter('train_acc')\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            if cuda:\n",
        "              inputs = inputs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            if epoch>=3 and q:\n",
        "              model.apply(torch.quantization.disable_observer)\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # print statistics\n",
        "            running_loss.update(loss.item(), outputs.shape[0])\n",
        "            acc.update(accuracy(outputs, labels), outputs.shape[0])\n",
        "            if i % 100 == 0:    # print every 100 mini-batches\n",
        "                print('[%d, %5d] ' %\n",
        "                    (epoch + 1, i + 1), running_loss, acc)\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "def test(model: nn.Module, dataloader: DataLoader, cuda=False) -> float:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, labels = data\n",
        "            if cuda:\n",
        "              inputs = inputs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-18T11:00:01.445395Z",
          "iopub.status.busy": "2023-12-18T11:00:01.444683Z",
          "iopub.status.idle": "2023-12-18T11:00:17.908485Z",
          "shell.execute_reply": "2023-12-18T11:00:17.907488Z",
          "shell.execute_reply.started": "2023-12-18T11:00:01.445356Z"
        },
        "id": "JifZQy1Qx1nw",
        "outputId": "3dcbbfc1-0d89-45bf-dde1-5d26385395e0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "image_set = pickle.load(open(\"Thesis/FashionMnist_set/fashionmnist_images.pkl\",'rb'))\n",
        "label_set = pickle.load(open(\"Thesis/FashionMnist_set/fashionmnist_label.pkl\",'rb'))\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),])\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MxQHJYiKFRq"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from torch.hub import load_state_dict_from_url\n",
        "except ImportError:\n",
        "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "from functools import partial\n",
        "from typing import Dict, Type, Any, Callable, Union, List, Optional\n",
        "from torch.ao.nn.quantized.modules.functional_modules import FloatFunctional\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.ff = torch.nn.quantized.FloatFunctional()\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        #out += identity\n",
        "        out = self.ff.add(out, identity)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class CifarResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(CifarResNet, self).__init__()\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = conv3x3(1, 16)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = CifarResNet(BasicBlock,[9]*3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TueUKyy2XlHT"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from typing import Dict, Type, Any, Callable, Union, List, Optional\n",
        "from torch import Tensor\n",
        "try:\n",
        "    from torch.hub import load_state_dict_from_url\n",
        "except ImportError:\n",
        "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "from torch.ao.nn.quantized.modules.functional_modules import FloatFunctional\n",
        "\n",
        "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        f_add = torch.nn.quantized.FloatFunctional()\n",
        "        new_v = f_add.add(new_v, divisor)\n",
        "        #new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class ConvBNActivation(nn.Sequential):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_planes: int,\n",
        "        out_planes: int,\n",
        "        kernel_size: int = 3,\n",
        "        stride: int = 1,\n",
        "        groups: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "        activation_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "        dilation: int = 1,\n",
        "    ) -> None:\n",
        "        padding = (kernel_size - 1) // 2 * dilation\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if activation_layer is None:\n",
        "            activation_layer = nn.ReLU6\n",
        "        super(ConvBNReLU, self).__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, dilation=dilation, groups=groups,\n",
        "                      bias=False),\n",
        "            norm_layer(out_planes),\n",
        "            activation_layer(inplace=True)\n",
        "        )\n",
        "        self.out_channels = out_planes\n",
        "\n",
        "\n",
        "# necessary for backwards compatibility\n",
        "ConvBNReLU = ConvBNActivation\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        inp: int,\n",
        "        oup: int,\n",
        "        stride: int,\n",
        "        expand_ratio: int,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        hidden_dim = int(round(inp * expand_ratio))\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        layers: List[nn.Module] = []\n",
        "        if expand_ratio != 1:\n",
        "            # pw\n",
        "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1, norm_layer=norm_layer))\n",
        "        layers.extend([\n",
        "            # dw\n",
        "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, norm_layer=norm_layer),\n",
        "            # pw-linear\n",
        "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "            norm_layer(oup),\n",
        "        ])\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "        self.out_channels = oup\n",
        "        self._is_cn = stride > 1\n",
        "        self.ff = torch.nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        if self.use_res_connect:\n",
        "            #return x + self.conv(x)\n",
        "            return self.ff.add(x, self.conv(x))\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 10,\n",
        "        width_mult: float = 1.0,\n",
        "        inverted_residual_setting: Optional[List[List[int]]] = None,\n",
        "        round_nearest: int = 8,\n",
        "        block: Optional[Callable[..., nn.Module]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        MobileNet V2 main class\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): Number of classes\n",
        "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
        "            inverted_residual_setting: Network structure\n",
        "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
        "            Set to 1 to turn off rounding\n",
        "            block: Module specifying inverted residual building block for mobilenet\n",
        "            norm_layer: Module specifying the normalization layer to use\n",
        "\n",
        "        \"\"\"\n",
        "        super(MobileNetV2, self).__init__()\n",
        "\n",
        "        if block is None:\n",
        "            block = InvertedResidual\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "\n",
        "        if inverted_residual_setting is None:\n",
        "            inverted_residual_setting = [\n",
        "                # t, c, n, s\n",
        "                [1, 16, 1, 1],\n",
        "                [6, 24, 2, 1],  # NOTE: change stride 2 -> 1 for CIFAR10/100\n",
        "                [6, 32, 3, 2],\n",
        "                [6, 64, 4, 2],\n",
        "                [6, 96, 3, 1],\n",
        "                [6, 160, 3, 2],\n",
        "                [6, 320, 1, 1],\n",
        "            ]\n",
        "\n",
        "        # only check the first element, assuming user knows t,c,n,s are required\n",
        "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
        "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
        "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "        features: List[nn.Module] = [ConvBNReLU(1, input_channel, stride=1, norm_layer=norm_layer)]  # NOTE: change stride 2 -> 1 for CIFAR10/100\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(block(input_channel, output_channel, stride, expand_ratio=t, norm_layer=norm_layer))\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1, norm_layer=norm_layer))\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(self.last_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # This exists since TorchScript doesn't support inheritance, so the superclass method\n",
        "        # (this one) needs to have a name other than `forward` that can be accessed in a subclass\n",
        "        x = self.features(x)\n",
        "        # Cannot use \"squeeze\" as batch-size can be 1\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "model = MobileNetV2(width_mult = 1.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-18T11:51:38.584818Z",
          "iopub.status.busy": "2023-12-18T11:51:38.583951Z",
          "iopub.status.idle": "2023-12-18T11:58:42.092927Z",
          "shell.execute_reply": "2023-12-18T11:58:42.091631Z",
          "shell.execute_reply.started": "2023-12-18T11:51:38.584782Z"
        },
        "id": "Ec0OO_ZUx1nx",
        "outputId": "29f536e6-e47e-4d34-8107-fa3b9816f032",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module, dataloader: DataLoader,testloader: DataLoader, cuda=False, q=False):\n",
        "    flagged = False\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-6)#optim.SGD(model.parameters(), lr=0.000001, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)#\n",
        "    model.train()\n",
        "    for epoch in range(200):  # loop over the dataset multiple times\n",
        "        if flagged:\n",
        "            break\n",
        "        else:\n",
        "            running_loss = AverageMeter('loss')\n",
        "            acc = AverageMeter('train_acc')\n",
        "            for i, data in enumerate(dataloader, 0):\n",
        "                # get the inputs; data is a list of [inputs, labels]\n",
        "                inputs, labels = data\n",
        "                if cuda:\n",
        "                  inputs = inputs.cuda()\n",
        "                  labels = labels.cuda()\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                if epoch>=3 and q:\n",
        "                  model.apply(torch.quantization.disable_observer)\n",
        "                # forward + backward + optimize\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                # print statistics\n",
        "                running_loss.update(loss.item(), outputs.shape[0])\n",
        "                acc.update(accuracy(outputs, labels), outputs.shape[0])\n",
        "                if i % 100 == 0:    # print every 100 mini-batches\n",
        "                    print('[%d, %5d] ' %\n",
        "                        (epoch + 1, i + 1), running_loss, acc)\n",
        "            score = test(model, testloader, cuda=True)\n",
        "            print('Accuracy of the network on the test images: {}% - FP32'.format(score))\n",
        "            score1 = test(model, dataloader, cuda=True)\n",
        "            print('Accuracy of the network on the adversarial set images: {}% - FP32'.format(score1))\n",
        "            if (score >= 93.30 and score1 >= 99.7):\n",
        "                flagged = True\n",
        "                #pass\n",
        "            model.train()\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(\"MobileNet_3it_Fashion_93.28acc.pkl\"))\n",
        "\n",
        "model.to(\"cuda\")\n",
        "model.eval()\n",
        "score = test(model, testloader, cuda=True)\n",
        "print('Accuracy of the network on the test images: {}% - FP32'.format(score))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "file = open(\"Thesis/MobileNetv2_x1_4/FashionMNIST/Train Iteration 3/train_mobilenet_hop_fashion_for_3it.pkl\",'rb')\n",
        "x_train_set = pickle.load(file)\n",
        "\n",
        "sample_size = 10000\n",
        "\n",
        "x_train_set = x_train_set[0:sample_size]\n",
        "#print(x_train_set.shape)\n",
        "y_train_set = label_set[0:sample_size]\n",
        "\n",
        "print(x_train_set.shape, y_train_set.shape, y_train_set[0])\n",
        "\n",
        "\n",
        "trainingSet = torch.utils.data.TensorDataset(torch.from_numpy(x_train_set).type(torch.FloatTensor), torch.from_numpy(y_train_set).type(torch.LongTensor))\n",
        "\n",
        "train_dev_sets = torch.utils.data.ConcatDataset([trainingSet])#, trainOriginalSet])\n",
        "def custom_collate(batch):\n",
        "    # Combine a list of samples into a batch\n",
        "    data, labels = zip(*batch)\n",
        "    data = torch.stack(data)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "retrain_loader = torch.utils.data.DataLoader(dataset=train_dev_sets, batch_size=64, num_workers=16, pin_memory=True, shuffle=True, collate_fn=custom_collate)\n",
        "\n",
        "train(model,retrain_loader,testloader,cuda=True,q=False)\n",
        "\n",
        "score = test(model, testloader, cuda=True)\n",
        "print('Accuracy of the network on the test images: {}% - FP32'.format(score))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w9yLdG7WqJw",
        "outputId": "8fc191fe-511b-407f-c4ff-db18a0833831"
      },
      "outputs": [],
      "source": [
        "score = test(model, testloader, cuda=True)\n",
        "print('Accuracy of the network on the test images: {}% - FP32'.format(score))\n",
        "score1 = test(model, retrain_loader, cuda=True)\n",
        "print('Accuracy of the network on the train images: {}% - FP32'.format(score1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-18T11:58:42.356906Z",
          "iopub.status.busy": "2023-12-18T11:58:42.356453Z",
          "iopub.status.idle": "2023-12-18T11:58:42.374650Z",
          "shell.execute_reply": "2023-12-18T11:58:42.373795Z",
          "shell.execute_reply.started": "2023-12-18T11:58:42.356881Z"
        },
        "id": "IhwVrYK5x1ny",
        "outputId": "22b56715-c03a-4fc8-d696-46f05a8d68cc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "score = test(model, testloader, cuda=True)\n",
        "print('Accuracy of the network on the test images: {}% - FP32'.format(score))\n",
        "torch.save(model.state_dict(), \"MobileNet_3it_Fashion_{}acc.pkl\".format(score))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3646861,
          "sourceId": 7182625,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4152726,
          "sourceId": 7183909,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4151988,
          "sourceId": 7229385,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30528,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
