{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-18T10:59:15.788631Z","iopub.status.busy":"2023-12-18T10:59:15.787823Z","iopub.status.idle":"2023-12-18T10:59:56.425178Z","shell.execute_reply":"2023-12-18T10:59:56.424048Z","shell.execute_reply.started":"2023-12-18T10:59:15.788586Z"},"trusted":true},"outputs":[],"source":["!pip3 install matplotlib colorama\n","!pip3 install adversarial-robustness-toolbox\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T10:59:56.428163Z","iopub.status.busy":"2023-12-18T10:59:56.427843Z","iopub.status.idle":"2023-12-18T11:00:01.443317Z","shell.execute_reply":"2023-12-18T11:00:01.442254Z","shell.execute_reply.started":"2023-12-18T10:59:56.428136Z"},"trusted":true},"outputs":[],"source":["from torch.quantization import MovingAverageMinMaxObserver\n","from torch.ao.quantization.observer import MinMaxObserver\n","from torch.quantization import QuantStub, DeQuantStub\n","from colorama import Fore, Style\n","import torch.nn as nn\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision import datasets\n","from art.estimators.classification import PyTorchClassifier\n","from art.utils import load_cifar10\n","from art.preprocessing.standardisation_mean_std import StandardisationMeanStdPyTorch\n","from art.attacks.evasion.hop_skip_jump import HopSkipJump\n","import time\n","import pickle\n","import os\n","from math import log10, sqrt\n","import cv2\n","from torch.utils.data import DataLoader\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","def PSNR(original, compressed):\n","    mse = np.mean((original.astype(np.float32) - compressed.astype(np.float32)) ** 2)\n","    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n","                  # Therefore PSNR have no importance.\n","        return 100\n","    max_pixel = 1.0  # Watch out. Floating Point Normalized max value\n","    psnr = 20 * log10(max_pixel / sqrt(mse))\n","    return psnr\n","\n","def mean(listed):\n","    return sum(listed)/len(listed)\n","\n","def accuracy(output, target):\n","    \"\"\" Computes the top 1 accuracy \"\"\"\n","    with torch.no_grad():\n","        batch_size = target.size(0)\n","\n","        _, pred = output.topk(1, 1, True, True)\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        correct_one = correct[:1].view(-1).float().sum(0, keepdim=True)\n","        return correct_one.mul_(100.0 / batch_size).item()\n","\n","def imshow(img):\n","    plt.imshow(img)\n","    plt.show(block=False)\n","    \n","def imshow_gray(img):\n","    plt.imshow(img, cmap = \"gray\")\n","    plt.show(block=False)\n","    \n","def grayscale(img):\n","    # R G B \n","    # Reshape the image to (32, 32, 3) instead of (3, 32, 32)\n","    reshaped_image = np.transpose(img, (1, 2, 0))\n","    # Convert the reshaped image to grayscale\n","    grayscale_image = np.dot(reshaped_image, [0.2989, 0.5870, 0.1140])\n","    # Normalize the grayscale image between 0 and 1\n","    grayscale_image = grayscale_image / 255.0\n","    # If you want to keep the shape as (1, 32, 32), reshape it back\n","    grayscale_image = np.expand_dims(grayscale_image, axis=0)\n","    return grayscale_image[0]\n","\n","def predict(img):\n","  img = torch.from_numpy(img)\n","  img = F.normalize(img, [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n","  return img.numpy()\n","\n","\n","def print_size_of_model(model):\n","    \"\"\" Prints the real size of the model \"\"\"\n","    torch.save(model.state_dict(), \"temp.p\")\n","    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n","    os.remove('temp.p')\n","\n","def train(model: nn.Module, dataloader: DataLoader, cuda=False, q=False):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.0001)#, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n","    model.train()\n","    for epoch in range(1):  # loop over the dataset multiple times\n","        running_loss = AverageMeter('loss')\n","        acc = AverageMeter('train_acc')\n","        for i, data in enumerate(dataloader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            if cuda:\n","              inputs = inputs.cuda()\n","              labels = labels.cuda()\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","            if epoch>=3 and q:\n","              model.apply(torch.quantization.disable_observer)\n","            # forward + backward + optimize\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            # print statistics\n","            running_loss.update(loss.item(), outputs.shape[0])\n","            acc.update(accuracy(outputs, labels), outputs.shape[0])\n","            if i % 100 == 0:    # print every 100 mini-batches\n","                print('[%d, %5d] ' %\n","                    (epoch + 1, i + 1), running_loss, acc)\n","    print('Finished Training')\n","\n","\n","def test(model: nn.Module, dataloader: DataLoader, cuda=False) -> float:\n","    correct = 0\n","    total = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for data in dataloader:\n","            inputs, labels = data\n","            if cuda:\n","              inputs = inputs.cuda()\n","              labels = labels.cuda()\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return 100 * correct / total\n","\n","def unpredict(img):\n","  img = torch.from_numpy(img)\n","  img = F.normalize(img, [-0.4914/0.2023, -0.4822/0.1994, -0.4465/0.2010], [1/0.2023, 1/0.1994, 1/0.2010])\n","  return img.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T11:00:01.445395Z","iopub.status.busy":"2023-12-18T11:00:01.444683Z","iopub.status.idle":"2023-12-18T11:00:17.908485Z","shell.execute_reply":"2023-12-18T11:00:17.907488Z","shell.execute_reply.started":"2023-12-18T11:00:01.445356Z"},"trusted":true},"outputs":[],"source":["# Step 1: Load the CIFAR10 dataset\n","\n","(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_cifar10()\n","\n","# Step 1a: Swap axes to PyTorch's NCHW format\n","\n","x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n","x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True, num_workers=16, pin_memory=True)\n","\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=False, num_workers=16, pin_memory=True)\n","\n","test_data = datasets.CIFAR10(root=\"./data\",train=False,download=True,transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=64)\n","\n","# show images\n","classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","unnorm_pics = torchvision.utils.make_grid(torch.from_numpy(x_train[0:5])).numpy()\n","unnormalized = np.transpose(unnorm_pics, (1, 2, 0) )\n","imshow(unnormalized)\n","\n","norm_pics = torchvision.utils.make_grid(torch.from_numpy(predict(x_train)[0:5])).numpy()\n","starter = np.transpose(norm_pics, (1, 2, 0) )\n","imshow(starter)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T11:51:38.584818Z","iopub.status.busy":"2023-12-18T11:51:38.583951Z","iopub.status.idle":"2023-12-18T11:58:42.092927Z","shell.execute_reply":"2023-12-18T11:58:42.091631Z","shell.execute_reply.started":"2023-12-18T11:51:38.584782Z"},"trusted":true},"outputs":[],"source":["def train(model: nn.Module, dataloader: DataLoader,testloader: DataLoader, cuda=False, q=False):\n","    flagged = False\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n","    model.train()\n","    for epoch in range(60):  # loop over the dataset multiple times\n","        if flagged:\n","            break\n","        else:\n","            running_loss = AverageMeter('loss')\n","            acc = AverageMeter('train_acc')\n","            for i, data in enumerate(dataloader, 0):\n","                # get the inputs; data is a list of [inputs, labels]\n","                inputs, labels = data\n","                if cuda:\n","                  inputs = inputs.cuda()\n","                  labels = labels.cuda()\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","                if epoch>=3 and q:\n","                  model.apply(torch.quantization.disable_observer)\n","                # forward + backward + optimize\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","                # print statistics\n","                running_loss.update(loss.item(), outputs.shape[0])\n","                acc.update(accuracy(outputs, labels), outputs.shape[0])\n","                if i % 100 == 0:    # print every 100 mini-batches\n","                    print('[%d, %5d] ' %\n","                        (epoch + 1, i + 1), running_loss, acc)\n","            score = test(model, testloader, cuda=True)\n","            print('Accuracy of the network on the test images: {}% - FP32'.format(score))\n","            score1 = test(model, dataloader, cuda=True)\n","            print('Accuracy of the network on the adversarial set images: {}% - FP32'.format(score1))\n","            if (score >= 91.28 and score1 >= 99.99):\n","                flagged = True\n","                #pass\n","            model.train()\n","    print('Finished Training')\n","\n","\n","model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)\n","#model.load_state_dict(torch.load(\"2nd_Iteration_retrained_model_quant_92.0acc.pkl\"))\n","model.to(\"cuda\")\n","model.eval()\n","score = test(model, testloader, cuda=True)\n","print('Accuracy of the network on the test images: {}% - FP32'.format(score))\n","\n","file = open(\"x_train_res20_fp_10k_3rd_Dataset.pkl\",'rb')\n","x_train_set = pickle.load(file)\n","\n","sample_size = 10000\n","\n","x_train_set = x_train_set[0:sample_size]\n","#print(x_train_set.shape)\n","y_train_set = np.empty((sample_size)).astype(np.int8)\n","\n","for i in range(sample_size):\n","    y_train_set[i] = np.where(y_train[i] == 1)[0][0]\n","    \n","print(x_train_set.shape, y_train_set.shape)\n","\n","\n","trainingSet = torch.utils.data.TensorDataset(torch.from_numpy(predict(x_train_set)).type(torch.FloatTensor), torch.from_numpy(y_train_set).type(torch.LongTensor))\n","\n","train_dev_sets = torch.utils.data.ConcatDataset([trainingSet])#, trainOriginalSet])\n","def custom_collate(batch):\n","    # Combine a list of samples into a batch\n","    data, labels = zip(*batch)\n","    data = torch.stack(data)\n","    labels = torch.tensor(labels, dtype=torch.long)\n","    return data, labels\n","\n","\n","retrain_loader = torch.utils.data.DataLoader(dataset=train_dev_sets, batch_size=64, num_workers=16, pin_memory=True, shuffle=True, collate_fn=custom_collate)\n","\n","train(model,retrain_loader,testloader,cuda=True,q=False)\n","\n","score = test(model, testloader, cuda=True)\n","print('Accuracy of the network on the test images: {}% - FP32'.format(score))\n","\n","#92.6 -> 92.18 adam,both_sets,1e-4 lr"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T11:58:42.356906Z","iopub.status.busy":"2023-12-18T11:58:42.356453Z","iopub.status.idle":"2023-12-18T11:58:42.374650Z","shell.execute_reply":"2023-12-18T11:58:42.373795Z","shell.execute_reply.started":"2023-12-18T11:58:42.356881Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), \"3rd_Iteration_retrained_model_quant_{}acc.pkl\".format(score))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T11:34:34.404460Z","iopub.status.busy":"2023-12-18T11:34:34.404003Z","iopub.status.idle":"2023-12-18T11:34:34.633905Z","shell.execute_reply":"2023-12-18T11:34:34.632877Z","shell.execute_reply.started":"2023-12-18T11:34:34.404422Z"},"trusted":true},"outputs":[],"source":["file = open(\"x_train_res20_fp_10k_3rd_Dataset.pkl\",'rb')\n","x_train_set = pickle.load(file)\n","\n","sample_size = 10000\n","\n","x_train_set = x_train_set[0:sample_size]\n","#print(x_train_set.shape)\n","y_train_set = np.empty((sample_size)).astype(np.int8)\n","\n","for i in range(sample_size):\n","    y_train_set[i] = np.where(y_train[i] == 1)[0][0]\n","    \n","print(x_train_set.shape, y_train_set.shape)\n","\n","\n","trainingSet = torch.utils.data.TensorDataset(torch.from_numpy(predict(x_train_set)).type(torch.FloatTensor), torch.from_numpy(y_train_set).type(torch.LongTensor))\n","\n","train_dev_sets = torch.utils.data.ConcatDataset([trainingSet])#, trainOriginalSet])\n","def custom_collate(batch):\n","    # Combine a list of samples into a batch\n","    data, labels = zip(*batch)\n","    data = torch.stack(data)\n","    labels = torch.tensor(labels, dtype=torch.long)\n","    return data, labels\n","\n","\n","retrain_loader = torch.utils.data.DataLoader(dataset=train_dev_sets, batch_size=64, num_workers=16, pin_memory=True, shuffle=True, collate_fn=custom_collate)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T11:34:39.015886Z","iopub.status.busy":"2023-12-18T11:34:39.015003Z","iopub.status.idle":"2023-12-18T11:34:40.804426Z","shell.execute_reply":"2023-12-18T11:34:40.803203Z","shell.execute_reply.started":"2023-12-18T11:34:39.015849Z"},"trusted":true},"outputs":[],"source":["#Sanity Check\n","model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)\n","#model.load_state_dict(torch.load(\"1st_Iteration_retrained_model_92.55acc.pkl\"))\n","model.to(\"cuda\")\n","model.eval()\n","score = test(model, retrain_loader, cuda=True)\n","print('Accuracy of the network on the 3rd adversarial set from 2nd iteration model (should be <20%): {}% - FP32'.format(score))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T13:17:23.372471Z","iopub.status.busy":"2023-12-17T13:17:23.371571Z","iopub.status.idle":"2023-12-17T14:01:33.203149Z","shell.execute_reply":"2023-12-17T14:01:33.202208Z","shell.execute_reply.started":"2023-12-17T13:17:23.372436Z"},"trusted":true},"outputs":[],"source":["# criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n","criterion = nn.CrossEntropyLoss()\n","\n","classifier = PyTorchClassifier(\n","    model=model,\n","    clip_values=(min_pixel_value, max_pixel_value),\n","    loss=criterion,\n","    optimizer=optimizer,\n","    preprocessing=((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n","    input_shape=(3, 32, 32),\n","    nb_classes=10,\n","    device_type = \"gpu\"\n",")\n","print(\"HopSkipJump Attack Initialization\")\n","attack = HopSkipJump(classifier,64,targeted = False,verbose = True)\n","#x_test_hop_res20org has 100 examples with 3200samples and 92% precision\n","x_test_hop_res20org_1 = attack.generate(x_train[0:400])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T14:03:17.937097Z","iopub.status.busy":"2023-12-17T14:03:17.936718Z","iopub.status.idle":"2023-12-17T14:03:17.946489Z","shell.execute_reply":"2023-12-17T14:03:17.945594Z","shell.execute_reply.started":"2023-12-17T14:03:17.937069Z"},"trusted":true},"outputs":[],"source":["with open(\"x_train_hop_res20_400_quantzed_dataset_2retrained.pkl\",'wb') as f:\n","    pickle.dump(x_test_hop_res20org_1,f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T14:03:50.619427Z","iopub.status.busy":"2023-12-17T14:03:50.619042Z","iopub.status.idle":"2023-12-17T14:03:50.701370Z","shell.execute_reply":"2023-12-17T14:03:50.700457Z","shell.execute_reply.started":"2023-12-17T14:03:50.619395Z"},"trusted":true},"outputs":[],"source":["from pandas import DataFrame\n","from scipy.stats.mstats import gmean\n","avg_20_norm = []\n","avg_20_grey = []\n","avg_20_norm_bf = []\n","avg_20_grey_bf = []\n","avg_20_norm_test = []\n","avg_20_grey_test = []\n","\n","for l in range(0,400):\n","    avg_20_norm.append(PSNR(x_train[l],x_test_hop_res20org_1[l]))\n","    avg_20_grey.append(PSNR(grayscale(x_train[l]),grayscale(x_test_hop_res20org_1[l])))\n","    \"\"\"avg_20_norm_bf.append(PSNR(x_train[l],x_train_set[l]))\n","    avg_20_grey_bf.append(PSNR(grayscale(x_train[l]),grayscale(x_train_set[l])))\n","    avg_20_norm_test.append(PSNR(x_test[l],x_test_set_1_retrain[l]))\n","    avg_20_grey_test.append(PSNR(grayscale(x_test[l]),grayscale(x_test_set_1_retrain[l])))\"\"\"\n","\n","print(Fore.RED + \"ResNet20 Normal Re-trained Average\")\n","\n","print(Style.RESET_ALL + \"RGB Average Result: \\n\",\n","          \"\\tGeometric Mean: \" + Fore.GREEN + \"{:.4f}dB\".format(gmean(avg_20_norm)) + Style.RESET_ALL + \" Mean: \" + Fore.GREEN + \"{:.4f}dB\".format(mean(avg_20_norm)),\n","          Style.RESET_ALL + \"\\nGrayscaled Result: \\n\",\n","          \"\\tGeometric Mean: \" + Fore.BLUE + \"{:.4f}dB\".format(gmean(avg_20_grey)) + Style.RESET_ALL + \" Mean: \" + Fore.BLUE + \"{:.4f}dB\".format(mean(avg_20_grey)),\n","      Fore.RED + \"\\nResNet20 Normal Pre-Retrain Average\",\n","      \"\"\"Style.RESET_ALL + \"\\nRGB Average Result: \\n\",\n","          \"\\tGeometric Mean: \" + Fore.GREEN + \"{:.4f}dB\".format(gmean(avg_20_norm_bf)) + Style.RESET_ALL + \" Mean: \" + Fore.GREEN + \"{:.4f}dB\".format(mean(avg_20_norm_bf)),\n","          Style.RESET_ALL + \"\\nGrayscaled Result: \\n\",\n","          \"\\tGeometric Mean: \" + Fore.BLUE + \"{:.4f}dB Mean: {:.4f}dB\".format(gmean(avg_20_grey_bf),mean(avg_20_grey_bf)),\n","      Fore.RED + \"\\nResNet20 Normal Pre-Retrain Average Testing Set\",\n","      Style.RESET_ALL + \"\\nRGB Average Result: \\n\",\n","          \"\\tGeometric Mean: \" + Fore.GREEN + \"{:.4f}dB\".format(gmean(avg_20_norm_test)) + Style.RESET_ALL + \" Mean: \" + Fore.GREEN + \"{:.4f}dB\".format(mean(avg_20_norm_test)),\n","          Style.RESET_ALL + \"\\nGrayscaled Result: \\n\",\n","          \"\\tGeometric Mean: \" + Fore.BLUE + \"{:.4f}dB Mean: {:.4f}dB\".format(gmean(avg_20_grey_test),mean(avg_20_grey_test))\"\"\"\n","          )\n","print(\"\\n\")\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3646861,"sourceId":7182625,"sourceType":"datasetVersion"},{"datasetId":4152726,"sourceId":7183909,"sourceType":"datasetVersion"},{"datasetId":4151988,"sourceId":7229385,"sourceType":"datasetVersion"}],"dockerImageVersionId":30528,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
